Due to the restrictions on LM rules and the partitioning of facts across the graph, nodes are able to
execute independently. Node computation happens non-deterministically since any node can be picked to run as long as it
contains enough facts to fire a derivation rule. Facts coming from other nodes will arrive in order of derivation but may be considered
partially and there is no particular order among the neighborhood.

LM programs can then be made concurrent by simply processing many nodes concurrently. In practice this can be done in many ways.
Given P processing units and N nodes, we place the N nodes in a work queue and then each processing unit performs work by taking
one node from the queue and then placing it back at the end of the queue. This trivial technique works but there is no consideration
for node connections and data locality. An improved technique is to partition the graph of N nodes into P subgraphs and then each
processing unit will only perform work on its subgraph.

In our implementation for multicores we also partition the graph among P threads but we also use node stealing when threads start to starve
in order to improve load balancing.
Our results show that LM programs running on multicores have good scalability. The implementation of the compiler and virtual machine and
the analysis of experimental results will be presented in a future paper.
